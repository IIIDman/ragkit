{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RAGKit Demo\n",
        "\n",
        "This notebook shows how to use RAGKit to build a simple document Q&A system.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/IIIDman/ragkit/blob/main/examples/RAGKit_Demo.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q ragkit pypdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Getting started\n",
        "\n",
        "The simplest way to use RAGKit:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragkit import RAGKit\n",
        "\n",
        "# This downloads the embedding model on first run (~90MB)\n",
        "rag = RAGKit()\n",
        "print(f\"Initialized: {rag}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adding content\n",
        "\n",
        "Let's add some text to query against:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "content = \"\"\"\n",
        "Retrieval-Augmented Generation (RAG) Explained\n",
        "\n",
        "RAG is a technique that combines retrieval-based and generation-based approaches\n",
        "for natural language processing tasks. It was introduced by Facebook AI Research\n",
        "in their 2020 paper.\n",
        "\n",
        "How RAG Works:\n",
        "1. Document Indexing: Documents are split into chunks and converted to vector embeddings\n",
        "2. Query Processing: User queries are also converted to embeddings\n",
        "3. Retrieval: The most similar document chunks are retrieved using vector similarity\n",
        "4. Generation: An LLM generates an answer using the retrieved context\n",
        "\n",
        "Benefits of RAG:\n",
        "- Access to up-to-date information beyond the LLM's training data\n",
        "- Reduced hallucination by grounding responses in actual documents\n",
        "- Ability to cite sources for generated answers\n",
        "- Cost-effective alternative to fine-tuning\n",
        "\n",
        "Common Use Cases:\n",
        "- Question answering over documents\n",
        "- Customer support chatbots\n",
        "- Research assistants\n",
        "- Code documentation search\n",
        "\"\"\"\n",
        "\n",
        "num_chunks = rag.add_text(content, metadata={\"source\": \"rag_explainer.txt\"})\n",
        "print(f\"Added {num_chunks} chunks\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Querying"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "answer = rag.query(\"What are the benefits of RAG?\")\n",
        "\n",
        "print(\"Q: What are the benefits of RAG?\")\n",
        "print(f\"\\nA: {answer.text}\")\n",
        "print(f\"\\nSources: {answer.sources}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "answer = rag.query(\"How does the retrieval step work?\")\n",
        "\n",
        "print(\"Q: How does the retrieval step work?\")\n",
        "print(f\"\\nA: {answer.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Searching without generation\n",
        "\n",
        "You can also just search for relevant chunks without generating an answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chunks = rag.search(\"use cases\", top_k=2)\n",
        "\n",
        "print(\"Search results for 'use cases':\")\n",
        "for i, chunk in enumerate(chunks, 1):\n",
        "    print(f\"\\n--- Result {i} ---\")\n",
        "    print(chunk.content[:200] + \"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Working with PDFs\n",
        "\n",
        "Adding a PDF is straightforward:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If you're in Colab, you can upload a file:\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "# pdf_path = list(uploaded.keys())[0]\n",
        "# rag.add_document(pdf_path)\n",
        "\n",
        "print(\"To add a PDF: rag.add_document('your_file.pdf')\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving your index\n",
        "\n",
        "You can save the index to disk and load it later:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save\n",
        "rag.save(\"my_ragkit_index\")\n",
        "\n",
        "# Load later with:\n",
        "# rag = RAGKit.load(\"my_ragkit_index\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "RAGKit handles:\n",
        "- Loading documents (PDF, text, markdown)\n",
        "- Creating embeddings\n",
        "- Vector search\n",
        "- Answer generation with sources\n",
        "- Saving/loading indexes\n",
        "\n",
        "All running locally."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
